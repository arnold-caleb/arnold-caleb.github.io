<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
  </script>

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="robots" content="noindex, nofollow">
  <meta name="description" content="Aspirational research vision for Arnold Caleb Asiimwe: extreme-ambition sandbox for ideas in multimodal intelligence and medicine.">
  <meta name="keywords" content="Asiimwe Arnold Caleb, Princeton, Columbia, Computer Vision, Multimodal Learning, Medicine, Neuroscience, Representation Learning, Generative Models">
  <meta name="author" content="Arnold Caleb Asiimwe">

  <link href="https://fonts.googleapis.com/css2?family=Noto+Sans:wght@400;600&display=swap" rel="stylesheet">
  <link href="css/styles.css" rel="stylesheet">
  <title>Arnold Caleb Asiimwe | Extreme Ambition Sandbox</title>
</head>
<body>
  <div class="container">

    <!-- LEFT: sticky rail -->

    <aside class="side-content" aria-label="Profile rail">
      <a href="arnold.jpg">
        <img src="./assets/profilepic.jpg" alt="Arnold Caleb Asiimwe" class="pfp">
      </a>
    
      <!-- Academic affiliation under photo -->
      <div class="glass note" style="margin-bottom:12px; font-size:14.5px; line-height:1.4;">
        <strong>Arnold Caleb Asiimwe</strong><br>
        <strong>PhD Student:</strong> <a href="https://www.princeton.edu/" class="sub-proj-link">Princeton Univ.</a><br>
        <strong>Advisor:</strong> <a href="https://www.cs.princeton.edu/~olgarus/" class="sub-proj-link">Olga Russakovsky</a>
      
        <!-- dotted separator -->
        <hr class="dashed-sep">

        üéì <strong>B.A.(2025)</strong> <a href="https://www.columbia.edu/" class="sub-proj-link">Columbia Univ.</a><br>
        <strong>Advisor:</strong> <a href="https://www.cs.columbia.edu/~vondrick/" class="sub-proj-link">Carl Vondrick</a>
      </div>
  
    
      <!-- Dynamic pills -->
      <div id="dynamic-pills" aria-label="focus tags">
        <span class="pill">multimodal</span>
        <span class="pill">clinical world models</span>
        <span class="pill">generative agents</span>
        <span class="pill">efficiency</span>
        <span class="pill">explainability</span>
      </div>
    </aside>

    <!-- RIGHT: content -->
    <main class="content">
      <!-- Subtle sticky micro-nav -->
      <div class="micro-nav" role="navigation" aria-label="Section navigation">
        <div style="display:flex; align-items:center; gap:14px; justify-content:space-between;">
          <div>
            <a href="#focus" class="navlink active">Focus</a>
            <a href="#projects" class="navlink">Projects</a>
            <a href="#updates" class="navlink">Updates</a>
            <a href="#teaching" class="navlink">Teaching</a>
            <a href="#copyright" class="navlink">Copyright</a>
          </div>
      
          <!-- Theme toggle -->
          <button id="theme-toggle" type="button" aria-label="Toggle dark mode"
            style="display:inline-flex; align-items:center; gap:8px; padding:6px 10px; border:1px solid rgba(122,122,196,.35);
                   background: var(--btn-bg); color: var(--ink); border-radius:999px; cursor:pointer; font-family:inherit; font-size:13px;">
            <span id="theme-emoji" aria-hidden="true">üåô</span>
            <span id="theme-label">Dark</span>
          </button>
        </div>
      </div>

      <!-- FOCUS -->
      <section id="focus" class="section" data-tags="multimodal,clinical world models,generative agents,efficiency,explainability,organic chemistry,drug discovery">
        <br>
        <h4 class="sub-head">Minds, Molecules, and Machines (MMM)</h4>
      
        <p class="paragraph">
          I aim to build multisensory AI systems that can perceive, predict, and act in complex clinical and scientific environments. My long-term goal is a <em>generalist scientific reasoning model</em> that learns not only from images, waveforms, and text, but also from the structured rules of chemistry and biology (<span class="badge">Nature 2026</span>, <span class="badge">Science 2026</span>). I would like to see AI that is efficient, transparent, and capable of proposing new hypotheses in medicine and drug discovery.
        </p>
        
        <p class="paragraph">
          I think about intelligence through the lens of <em>world models</em>. If \( s_t \) is a latent state over patient physiology or molecular conformation, I study models \( p(s_{t+1}\!\mid\!s_t, a_t, x_t) \) that forecast futures under counterfactual actions \( a_t \) using multimodal observations \( x_t \) (<span class="badge">NeurIPS 2027</span>, <span class="badge">ICML 2027</span>). This spans from predicting outcomes in intensive care units to simulating catalytic cycles in asymmetric organic reactions.
        </p>
        
        <p class="paragraph">
          My curiosity extends to the <span class="text-background">intersection of organic chemistry and machine learning</span>. In particular, I am fascinated by <strong>asymmetric catalysis</strong> (e.g., Sharpless epoxidations and enantioselective oxidations) as both a chemical phenomenon and a metaphor for learning: how small asymmetries in priors or architectures can bias a system toward profoundly different outcomes (<span class="badge">JACS 2029</span>, <span class="badge">Nature Chemistry 2028</span>). I study whether reinforcement learning with asymmetric inductive biases can accelerate <em>de novo</em> drug design, optimizing molecules in high-dimensional chemical space (<span class="badge">CVPR 2026</span>, <span class="badge">CVPR 2027</span>).
        </p>
        
        <!-- <p class="paragraph">
          Ultimately, I want to unify perception across minds, molecules, and machines‚Äîusing computer vision and cognitive neuroscience to understand <em>how we see</em>, and using reinforcement learning to let AI <em>play</em> with virtual chemistry and biology. My ambition is a system that can watch a cell divide, read a patient chart, and imagine the catalytic path of a drug candidate‚Äîall within a single representational framework.
        </p>  -->
        
        <p class="paragraph">
          Previously, I completed my undergraduate studies at Columbia University with formative mentorship from
          <a href="https://www.cs.columbia.edu/~vondrick/" class="sub-proj-link">Carl Vondrick</a>. 
          I am also fortunate to have been mentored by <a href="https://www.engineering.columbia.edu/faculty-staff/directory/christos-papadimitriou" class="sub-proj-link">Prof. Christos Papadimitriou</a>, <a href="https://www.cs.columbia.edu/~kaoutar/" class="sub-proj-link">Kaoutar El Maghraoui</a>, and <a href="https://www.cs.columbia.edu/~shree/" class="sub-proj-link">Prof. Shree Nayar</a> who recommended me for my PhD.
        </p>
      </section>


      
      <!-- PROJECTS -->
      <section id="projects" class="section" data-tags="projects,world models,foundation models,alignment,forecasting,bedside AI">
        <br>
        <h4 class="sub-head">Research</h4>
        <br>

        <div class="research-project glass">
          <a href="drafts/unified-sensorium.pdf" class="sub-proj">Unified Sensorium: A Foundation Model for Radiology, Pathology, & EHR</a><br>
          <span class="badge">Hypothetical</span><br>
          <a href="#" class="sub-proj-authors">A.C. Asiimwe, O. Russakovsky, E.B. Issa</a><br>
          <a href="https://www.nature.com/" class="sub-proj-proj">Target journal: Nature</a><br>
          <span>
            <a href="drafts/unified-sensorium.pdf" class="link">Preprint (dummy)</a> |
            <a href="#" class="link">Project Page</a>
          </span>
          <div class="note">Joint tokenization of pixels, patches, waveforms, and notes with a single latent ‚Äúpatient state‚Äù space; enables cross-modal retrieval and zero-shot clinical QA.</div>
        </div>

        <hr>

        <div class="research-project glass">
          <a href="drafts/clinician-in-the-loop-alignment.pdf" class="sub-proj">Clinician-in-the-Loop Alignment for Generative Diagnostic Policies</a><br>
          <span class="badge">Aspirational Draft</span><br>
          <a href="#" class="sub-proj-authors">A.C. Asiimwe, M. Salvatore, P. Rajpurkar</a><br>
          <a href="https://www.nature.com/" class="sub-proj-proj">Target journal: Nature Communications</a><br>
          <span>
            <a href="drafts/clinician-in-the-loop-alignment.pdf" class="link">Preprint (dummy)</a> |
            <a href="#" class="link">Ethics & Safety Card</a>
          </span>
          <div class="note">Preference data from attending physicians guides policy gradients; integrates calibration and explanation objectives for safe interactive use.</div>
        </div>

        <hr>

        <div class="research-project glass">
          <a href="drafts/m-planes.pdf" class="sub-proj">\( \mathcal{M} \)-Planes: Factorized Motion Planes for Medical Video Forecasting</a>
          <br><span class="badge">Vision</span><br>
          <a href="#" class="sub-proj-authors">A.C. Asiimwe & C. Vondrick</a><br>
          <a href="#" class="sub-proj-proj">ArXiv (planned)</a><br>
          <span>
            <a href="drafts/m-planes.pdf" class="link">Preprint (dummy)</a> |
            <a href="#" class="link">Project Page</a> |
            <a href="#" class="link">Demo</a>
          </span>
          <div class="note">Decomposes organ motion into sparse planes for echo/video; improves sample efficiency and long-horizon prediction with structured latent dynamics.</div>
        </div>

        <hr>

        <div class="research-project glass">
          <a href="drafts/efficient-explainable-foundations.pdf" class="sub-proj">Efficient & Explainable Foundation Models for Bedside AI</a>
          <br><span class="badge">Hypothetical</span><br>
          <a href="#" class="sub-proj-authors">A.C. Asiimwe, K. El Maghraoui</a><br>
          <a href="https://www.nature.com/" class="sub-proj-proj">Target journal: Nature Machine Intelligence</a><br>
          <span>
            <a href="drafts/efficient-explainable-foundations.pdf" class="link">Preprint (dummy)</a> |
            <a href="#" class="link">Code (TBD)</a>
          </span>
          <div class="note">Neural architecture search + distillation under hardware constraints; integrates concept-based explanations with verified sparsity.</div>
        </div>
      </section>

      <hr>

      <!-- UPDATES -->
      <section id="updates" class="section" data-tags="updates,prototypes,tokenizers,simulators">
        <h4 class="sub-head">Updates</h4>
        <div class="text-background note">
          Sep 2025: Drafted <em>World-Model Hospitals</em> simulation spec; building toy ICU with scripted labs, vitals, and imaging APIs.
        </div><br><br>
        <div class="text-background note">
          Aug 2025: Prototype tokenizer for <em>Unified Sensorium</em> with shared latent patient state.
        </div>
      </section>

      <hr>

      <!-- TEACHING (moved to end) -->
      <section id="teaching" class="section" data-tags="teaching,mentorship,Princeton,Columbia">
        <h4 class="sub-head">Teaching</h4>
        <div>
          <span><a href="#" class="sub-proj-link">Inference in Action (Probabilistic Reinforcement Learning)</a><br>
            <span class="sub-proj-proj">Graduate Course ‚Äî Princeton<br>
              <span>Fall 2026 (Prof. Ben Eysenbach)</span>
            </span>
          </span><br><br>

          <span><a href="https://www.cs.columbia.edu/~aa4870/high-performance-machine-learning" class="sub-proj-link">High Performance Machine Learning</a><br>
            <span class="sub-proj-proj">Graduate Teaching Assistant<br>
              <span>Fall 2024, Spring 2025 (Prof. Kaoutar El Maghraoui)</span>
            </span>
          </span><br><br>

          <span><a href="https://cs.columbia.edu/~vondrick" class="sub-proj-link">Computer Vision II</a><br>
            <span class="sub-proj-proj">Graduate Teaching Assistant<br>
              <span>Spring 2024, Spring 2025 (Prof. Carl Vondrick)</span>
            </span>
          </span><br><br>

          <span><a href="https://www.college.columbia.edu/core-curriculum/classes/frontiers-science" class="sub-proj-link">Frontiers of Science</a><br>
            <span class="sub-proj-proj">Teaching Assistant<br>
              <span>Spring 2022, 2023, 2024</span>
            </span>
          </span><br><br>

          <span><a href="#" class="sub-proj-link">Machine Learning & Python Fundamentals</a><br>
            <span class="sub-proj-proj">Laidlaw Scholar Graduate Tutor<br>
              <span>Summer A 2024</span>
            </span>
          </span>
        </div>
      </section>

      <hr>

      <!-- COPYRIGHT -->
      <section id="copyright" class="section" data-tags="license,attribution,sandbox">
        <h4 class="sub-head">Copyright & License</h4>
        <div class="copyright">
          <span>¬© 2025 Arnold Caleb Asiimwe.</span>
          <span>Design & content on this sandbox are provided for personal planning and mindset only.</span>
          <span>Aspirational paper titles and link are placeholders and <strong>not</strong> for citation.</span>
          <span>Unless otherwise noted, code & text on this page are released under <a class="sub-proj-link" href="#">CC BY-NC 4.0</a>.</span>
        </div>
      </section>

      <hr style="opacity:.3; margin-top:24px;">
    </main>
  </div>

  <!-- Neural Network Background Canvas -->
  <canvas id="neural-canvas"></canvas>

  <script src="js/navigation.js"></script>
  <script src="js/theme.js"></script>
  <script src="js/glass-effects.js"></script>
  <script src="js/neural-background.js"></script>
</body>
</html>